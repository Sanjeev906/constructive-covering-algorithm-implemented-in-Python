{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "sys.path.append(os.path.join(ROOT_DIR,r'mod'))\n",
    "from core import DataTrain\n",
    "from datatest import DataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_path = os.path.join(ROOT_DIR,r'data_set\\data_transformed\\raw_dataset.out')\n",
    "full_result_path = os.path.join(ROOT_DIR,r'result\\full\\full_result.json')\n",
    "train_minmax_path = os.path.join(ROOT_DIR,r'minmax_out\\train_minmax.out')\n",
    "test_minmax_path = os.path.join(ROOT_DIR,r'minmax_out\\test_minmax.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = np.loadtxt(raw_dataset_path, delimiter = ',')\n",
    "# print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 17\n"
     ]
    }
   ],
   "source": [
    "m,n = raw_dataset.shape\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold划分\n",
    "n_splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据类别数\n",
    "classes = 7\n",
    "full_result = {}\n",
    "for i in range(classes):\n",
    "    full_result[str(i)] = []\n",
    "with open(full_result_path, 'w') as f_full_result:\n",
    "    json.dump(full_result,f_full_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次迭代测试:\n",
      "正确率: 44.12 %\n",
      "对测试集所有数据的测试结果\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "------------------------------------------------------------------\n",
      "对测试集所有数据的预测结果\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "==================================================================\n",
      "第2次迭代测试:\n",
      "正确率: 88.24 %\n",
      "对测试集所有数据的测试结果\n",
      "[[19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    9.    0.    0.    0.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    9.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.  ]\n",
      " [ 0.    7.    0.    0.    0.    0.    0.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    6.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    7.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    3.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    2.    0.    0.  ]\n",
      " [18.    0.    0.    0.    0.    0.    0.  ]\n",
      " [16.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    7.    0.    0.    0.    0.    0.  ]\n",
      " [ 8.06  3.37  0.75  1.14  0.85  3.84  2.43]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.    0.    0.    0.    3.    0.    0.  ]\n",
      " [ 0.    6.    0.    0.    0.    0.    0.  ]\n",
      " [12.    0.    0.    0.    0.    0.    0.  ]\n",
      " [19.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    5.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    9.    0.    0.    0.  ]\n",
      " [11.36  7.51  1.45  1.92  1.33  2.5   2.02]\n",
      " [ 9.    0.    2.    0.    1.    0.    0.  ]\n",
      " [18.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 7.2   2.91  0.72  1.05  0.79  2.5   1.99]\n",
      " [ 0.    0.    0.    0.    0.    0.    1.  ]\n",
      " [ 0.    6.    0.    0.    0.    0.    0.  ]]\n",
      "------------------------------------------------------------------\n",
      "对测试集所有数据的预测结果\n",
      "[0, 0, 3, 0, 3, 6, 6, 6, 1, 0, 1, 1, 4, 4, 0, 0, 1, 0, 0, 6, 0, 0, 4, 1, 0, 0, 1, 3, 0, 0, 0, 0, 6, 1]\n",
      "==================================================================\n",
      "第3次迭代测试:\n",
      "正确率: 96.97 %\n",
      "对测试集所有数据的测试结果\n",
      "[[ 0.    0.    1.   18.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [43.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.   13.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.   18.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    4.    0.  ]\n",
      " [13.24  9.03  1.32  2.53  1.22 17.66  4.77]\n",
      " [43.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.   12.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.   18.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    1.   18.    0.    0.    0.  ]\n",
      " [ 0.   15.    0.    0.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    6.  ]\n",
      " [ 0.    7.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    1.   18.    0.    0.    0.  ]\n",
      " [ 0.    0.    3.    0.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [29.    0.    0.    0.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [43.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.   16.    0.    0.    0.    0.    0.  ]\n",
      " [16.21  7.19  2.03  2.49  1.23  4.3   3.8 ]\n",
      " [30.    0.    0.    0.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.   14.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    4.    0.  ]\n",
      " [ 0.    0.    0.    0.    3.    0.    0.  ]\n",
      " [ 0.    0.    0.   18.    0.    0.    0.  ]\n",
      " [44.    0.    0.    0.    0.    0.    0.  ]]\n",
      "------------------------------------------------------------------\n",
      "对测试集所有数据的预测结果\n",
      "[3, 0, 0, 1, 3, 0, 5, 5, 0, 1, 3, 0, 3, 1, 0, 0, 6, 1, 3, 2, 0, 0, 0, 0, 1, 0, 0, 0, 3, 5, 4, 3, 0]\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "lter = 1\n",
    "kf = KFold(n_splits,shuffle=True)\n",
    "for train_index,test_index in kf.split(raw_dataset):\n",
    "    train_data = np.zeros([1,n])\n",
    "    test_data = np.zeros([1,n])\n",
    "    for i in train_index:\n",
    "        row_temp = np.empty([1,n])\n",
    "        for j in range(n):\n",
    "            row_temp[0][j] = raw_dataset[i][j]\n",
    "        train_data = np.append(train_data, row_temp, axis = 0)\n",
    "    train_data = np.delete(train_data,0,axis = 0)\n",
    "    # print(train_data)\n",
    "    train_data_nontag = train_data[...,0:n-1]\n",
    "    train_tag = train_data[...,n-1]\n",
    "    tm = train_tag.size\n",
    "    train_tag = train_tag.reshape(tm,1)\n",
    "    # print(train_tag)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler().fit(raw_dataset[...,0:n-1])\n",
    "    train_minmax = min_max_scaler.transform(train_data_nontag)\n",
    "    train_minmax = np.concatenate((train_minmax,train_tag), axis=1)\n",
    "    # print(train_minmax)\n",
    "    np.savetxt(train_minmax_path, train_minmax, delimiter=',')\n",
    "    train_process = DataTrain(lter,classes,train_minmax_path)\n",
    "    train_process.start_train()\n",
    "    # ------------------------------------------------------------------\n",
    "    for i in test_index:\n",
    "        row_temp = np.empty([1,n])\n",
    "        for j in range(n):\n",
    "            row_temp[0][j] = raw_dataset[i][j]\n",
    "        test_data = np.append(test_data, row_temp, axis = 0)\n",
    "    test_data = np.delete(test_data,0,axis = 0)\n",
    "    # print(test_data)\n",
    "    test_data_nontag = test_data[...,0:n-1]\n",
    "    test_tag = test_data[...,n-1]\n",
    "    tem = test_tag.size\n",
    "    test_tag = test_tag.reshape(tem,1)\n",
    "    # print(test_tag)\n",
    "    test_minmax = min_max_scaler.transform(test_data_nontag)\n",
    "    test_minmax = np.concatenate((test_minmax,test_tag), axis=1)\n",
    "    # print(test_minmax)\n",
    "    print('第' + str(lter) + '次迭代测试:')\n",
    "    np.savetxt(test_minmax_path, test_minmax, delimiter=',')\n",
    "    test_process = DataTest(classes,test_minmax_path,full_result_path)\n",
    "    test_process.start_test()\n",
    "    # ------------------------------------------------------------------\n",
    "    # 合并结果\n",
    "    present_result_path = ROOT_DIR + r'\\result\\result' + str(lter) + '.json'\n",
    "    with open(present_result_path, 'r') as f_present_result:\n",
    "        present_result = json.load(f_present_result)\n",
    "    with open(full_result_path, 'r') as f_full_result:\n",
    "        full_result = json.load(f_full_result)\n",
    "    for cla in range(classes):\n",
    "        full_result[str(int(cla))].extend(present_result[str(int(cla))])\n",
    "    with open(full_result_path, 'w') as f_full_result:\n",
    "        json.dump(full_result,f_full_result)\n",
    "    # ------------------------------------------------------------------\n",
    "    del train_process\n",
    "    lter = lter + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
